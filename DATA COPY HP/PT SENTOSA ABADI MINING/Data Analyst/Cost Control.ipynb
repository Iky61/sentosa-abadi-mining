{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "378434f0-2bad-4490-8d15-519e13fbf21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import re\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# setting pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# setting seaborn\n",
    "sns.set_palette('Spectral')\n",
    "sns.set_context('notebook', font_scale=1)\n",
    "sns.set_style('whitegrid')\n",
    "sns.set(rc={\"axes.facecolor\":\"#FFF9ED\",\"figure.facecolor\":\"#FFF9ED\"})\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdbd357-ea6d-450e-a489-1545c591d97f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **Define Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "206d3587-4906-49b4-802c-5fd67740bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to transform timedelat to minute\n",
    "def timedelta_to_hour(timedelta_str):\n",
    "    # Konversi timedelta string ke timedelta object\n",
    "    timedelta_obj = pd.to_timedelta(timedelta_str)\n",
    "    \n",
    "    # Hitung total detik dalam timedelta\n",
    "    total_seconds = timedelta_obj.total_seconds()\n",
    "    \n",
    "    # Konversi total detik ke jam\n",
    "    total_hour = total_seconds / 3600\n",
    "    \n",
    "    return total_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b453418a-3d27-4f03-89c7-1a2ff181edeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create transform curency\n",
    "def rupiah(value):\n",
    "    str_value = str(value)\n",
    "    separate_decimal = str_value.split(\".\")\n",
    "    after_decimal = separate_decimal[0]\n",
    "    before_decimal = separate_decimal[1]\n",
    "\n",
    "    reverse = after_decimal[::-1]\n",
    "    temp_reverse_value = \"\"\n",
    "\n",
    "    for index, val in enumerate(reverse):\n",
    "        if (index + 1) % 3 == 0 and index + 1 != len(reverse):\n",
    "            temp_reverse_value = temp_reverse_value + val + \".\"\n",
    "        else:\n",
    "            temp_reverse_value = temp_reverse_value + val\n",
    "\n",
    "    temp_result = temp_reverse_value[::-1]\n",
    "\n",
    "    return \"Rp \" + temp_result + \",\" + before_decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14c489ca-9714-4e67-8208-21a5371ad799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similairty_sentence(text1, text2):\n",
    "    # Menggunakan regex untuk memisahkan teks berdasarkan simbol dan spasi\n",
    "    tokens1 = ''.join(re.split(r'\\W+', text1.lower()))\n",
    "    tokens2 = ''.join(re.split(r'\\W+', text2.lower()))\n",
    "\n",
    "    # Menghitung frekuensi kata dalam masing-masing teks\n",
    "    counter1 = Counter(tokens1)\n",
    "    counter2 = Counter(tokens2)\n",
    "\n",
    "    # Menghitung dot product\n",
    "    dot_product = sum(counter1[word] * counter2[word] for word in counter1 if word in counter2)\n",
    "\n",
    "    # Menghitung magnitudo dari vektor tiap teks\n",
    "    magnitude1 = math.sqrt(sum(counter1[word] ** 2 for word in counter1))\n",
    "    magnitude2 = math.sqrt(sum(counter2[word] ** 2 for word in counter2))\n",
    "\n",
    "    # Menghindari pembagian oleh nol\n",
    "    if magnitude1 == 0 or magnitude2 == 0:\n",
    "        return 0\n",
    "\n",
    "    # Menghitung cosine similarity\n",
    "    similarity = dot_product / (magnitude1 * magnitude2)\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7133e0f-9856-4aa7-8989-ab3500d08446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path, sheet=''):\n",
    "    list_file = os.listdir(path)\n",
    "    try:\n",
    "        list_file.remove('.DS_Store')\n",
    "    except:\n",
    "        None\n",
    "    \n",
    "    msg = []\n",
    "    for i in list_file:\n",
    "        if sheet == '':\n",
    "            msg.append(pd.read_excel(path + '/' + i))\n",
    "        else:\n",
    "            msg.append(pd.read_excel(path + '/' + i, sheet_name=sheet))\n",
    "    msg = pd.concat(msg)\n",
    "    msg.reset_index(drop=True, inplace=True)\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cbbbbf-c75d-4544-831f-29c7433f4295",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **ETL : Extracting, Transforming, Loading**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84432fb-4e2d-45f5-9755-3679e2b9c8a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Maintenance.Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bb1051b-9bac-4670-931a-24a6bbc3a7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mr = '/Users/dickyaryanto/Documents/PT Sentosa Abadi Mining/Data/maintenance request'\n",
    "df2 = read_file(path_mr)\n",
    "\n",
    "df2['Broken Date'] = df2['Broken Date'].apply(lambda x: str(x))\n",
    "df2['Request Date'] = df2['Request Date'].apply(lambda x: str(x))\n",
    "df2['Scheduled Date'] = df2['Scheduled Date'].apply(lambda x: str(x))\n",
    "df2['Completion Date'] = df2['Completion Date'].apply(lambda x: str(x))\n",
    "\n",
    "def transformasi_nan_format(x):\n",
    "    con = str(x)\n",
    "    if con == 'NaT' or con == 'nan':\n",
    "        msg = np.NaN\n",
    "    else:\n",
    "        msg = x\n",
    "    return msg\n",
    "\n",
    "df2['Broken Date'] = df2['Broken Date'].apply(transformasi_nan_format)\n",
    "df2['Request Date'] = df2['Request Date'].apply(transformasi_nan_format)\n",
    "df2['Scheduled Date'] = df2['Scheduled Date'].apply(transformasi_nan_format)\n",
    "df2['Completion Date'] = df2['Completion Date'].apply(transformasi_nan_format)\n",
    "\n",
    "df2 = df2.ffill()\n",
    "\n",
    "path_p = '/Users/dickyaryanto/Documents/PT Sentosa Abadi Mining/Data/stock picking'\n",
    "picking = read_file(path_p)\n",
    "\n",
    "df2['Request Date'] = pd.to_datetime(df2['Request Date'])\n",
    "df2 = df2[df2['Request Date'].dt.year>=2023]\n",
    "\n",
    "# merge data df2 terkecuali berstatus Cancelles\n",
    "def get_service(x):\n",
    "    if x == '':\n",
    "        msg = 'Service'\n",
    "    else:\n",
    "        msg = x\n",
    "    return msg\n",
    "    \n",
    "df2['Picking Line/Status'] = df2['Picking Line/Status'].apply(get_service)\n",
    "\n",
    "df2 = df2[df2['Picking Line/Status'].isin(['Service','Ready','Done'])]\n",
    "\n",
    "df2 = df2.merge(picking[['Reference','Stock Moves/Product','Stock Moves/Quantity Done','Stock Moves/Unit of Measure']], left_on='Picking Line/Reference', right_on='Reference', how='left')\n",
    "\n",
    "# refill data\n",
    "df2_1 = df2[df2['Picking Line/Status']=='Service']\n",
    "df2_1['Reference'] = '-'\n",
    "df2_1['Stock Moves/Product'] = '-'\n",
    "df2_1['Stock Moves/Quantity Done'] = 0\n",
    "df2_1['Stock Moves/Unit of Measure'] = '-'\n",
    "\n",
    "df2_2 = df2[df2['Picking Line/Status']!='Service']\n",
    "df2 = pd.concat([df2_1, df2_2])\n",
    "\n",
    "# extract maintenance.request\n",
    "df = df2.copy()\n",
    "df.columns = ['_'.join(i.split()).lower() for i in df.columns]\n",
    "df.drop(columns='reference', inplace=True)\n",
    "\n",
    "# transformasi tipe data\n",
    "df['request_date'] = pd.to_datetime(df['request_date'])\n",
    "df = df[df.request_date.dt.year >= 2023]\n",
    "\n",
    "df.columns=['company','spk','stage','broken','request','schedule','done','oprator','category_equipment','equipment_name',\n",
    "            'equipment_code','hm','km','requirement_type','category_maintenance','picking_reference','picking_status','note','description','qty','uom']\n",
    "df['oprator_name'] = df.oprator.apply(lambda x: str(x).split('] ')[-1])\n",
    "df = df[df.spk!='D85-06']\n",
    "df = df[df.spk!='PC200-12']\n",
    "df['spk'] = df.spk.apply(lambda x: int(str(x).split('/')[-1]))\n",
    "df.sort_values('spk', ascending=False, inplace=True)\n",
    "df['spk'] = df['spk'].astype(str)\n",
    "\n",
    "def get_description(x):\n",
    "    if x == False:\n",
    "        msg = 'Service Only'\n",
    "    else:\n",
    "        msg = x\n",
    "    return msg\n",
    "\n",
    "df['description'] = df['description'].apply(get_description)\n",
    "df['uom'] = df['uom'].apply(lambda x: str(x).upper())\n",
    "\n",
    "df['broken'] = pd.to_datetime(df['broken'])\n",
    "df['request'] = pd.to_datetime(df['request'])\n",
    "df['schedule'] = pd.to_datetime(df['schedule'])\n",
    "df['done'] = pd.to_datetime(df['done'])\n",
    "df['hm'] = df['hm'].astype(float)\n",
    "df['km'] = df['km'].astype(float)\n",
    "\n",
    "_ = df[df.category_equipment==False]\n",
    "_['category_equipment'] = 'Tidak Diketahui'\n",
    "_['equipment_name'] = 'Tidak Diketahui'\n",
    "_['equipment_code'] = 'Tidak Diketahui'\n",
    "__ = df[df.category_equipment!=False]\n",
    "df = pd.concat([_, __]).sort_values('spk', ascending=False)\n",
    "\n",
    "def retext_equpment_name(x):\n",
    "    if x in ['HINO ZY1EWPD-XS','HINO ZY1EWRD-XS','HINO ZY1EWRN-XS']:\n",
    "        msg = 'HINO ZY'\n",
    "    elif x in ['HINO ZS1EPPD-XS']:\n",
    "        msg = 'HINO ZS'\n",
    "    else:\n",
    "        msg = x\n",
    "    return msg\n",
    "\n",
    "df['equipment_name'] = df['equipment_name'].apply(retext_equpment_name)\n",
    "df['category_maintenance'].replace('TRYE', 'TYRE', inplace=True)\n",
    "df['category_maintenance'].replace('TRYE (Archive)', 'TYRE', inplace=True)\n",
    "\n",
    "# buat table category maintenance\n",
    "tbl_cm = df[df.category_maintenance!=False][['category_maintenance','description']].drop_duplicates()\n",
    "\n",
    "def get_correct_category_maintenance(x):\n",
    "    n = tbl_cm[tbl_cm.description == x]\n",
    "    if len(n) == 0:\n",
    "        try:\n",
    "            n = tbl_cm.copy()\n",
    "            n['score'] = n.description.apply(lambda i: similairty_sentence(x, i))\n",
    "            n = n.sort_values('scor', ascending=False)\n",
    "            msg = n['category_maintenance'].uniqeu().tolist()[0]\n",
    "        except:\n",
    "            msg = x\n",
    "    else:\n",
    "        msg = n['category_maintenance'].unique().tolist()[0]\n",
    "    return msg \n",
    "\n",
    "df_ = df[df.category_maintenance!=False]\n",
    "df__ = df[df.category_maintenance==False]\n",
    "\n",
    "df__['category_maintenance'] = df__.description.apply(get_correct_category_maintenance)\n",
    "df = pd.concat([df_, df__])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c276c9-da0e-4f5d-8951-229493b8fe54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d129b8ad-97cb-4a55-939f-765c4cfd85d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f81ec16-f9b2-4b31-9675-c0df5cb86018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364e55b0-25ee-4244-bfb3-dedf29f0e0e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "335328ef-45ce-41c4-b21c-7ac5af51fb06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Product.Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1804ed5-659c-4814-97dc-a589d45263a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract product.template\n",
    "path_pt = '/Users/dickyaryanto/Documents/PT Sentosa Abadi Mining/Data/product template'\n",
    "product = read_file(path_pt)\n",
    "product.columns = ['_'.join(i.lower().split()) for i in product.columns]\n",
    "product['unit_of_measure'] = product['unit_of_measure'].apply(lambda x: str(x).upper())\n",
    "product['name2'] = '#' + product['name'] + '#' + product['unit_of_measure']\n",
    "product.drop_duplicates(subset='product', inplace=True)\n",
    "\n",
    "# merge data product untuk dapatkan cost\n",
    "df = pd.merge(df, product[['name', 'product','cost']], left_on='description', right_on='product', how='left').drop(columns='product')\n",
    "df['cost'].fillna(0, inplace=True)\n",
    "df['cost'] = df['cost'].astype(float)\n",
    "df['qty'] = df['qty'].astype(float)\n",
    "\n",
    "df['description'] = df['description'].apply(lambda x: str(x))\n",
    "df['qty'] = df['qty'].apply(lambda x: str(x))\n",
    "df['cost'] = df['cost'].apply(lambda x: str(x))\n",
    "\n",
    "def get_decription(x):\n",
    "    con = str(x)\n",
    "    if con == 'nan':\n",
    "        msg='Service'\n",
    "    else:\n",
    "        msg = x\n",
    "    return msg\n",
    "\n",
    "def get_qty(x):\n",
    "    con = str(x)\n",
    "    if con == 'nan':\n",
    "        msg=0\n",
    "    else:\n",
    "        msg = x\n",
    "    return msg\n",
    "\n",
    "df['description'] = df.description.apply(get_description)\n",
    "df['qty'] = df['qty'].apply(get_qty)\n",
    "df['cost'] = df['cost'].apply(get_qty)\n",
    "df = df.rename(columns={'name':'description_2'})\n",
    "df['description_2'] = df['description_2'].apply(lambda x: str(x))\n",
    "df['description_2'] = df.description_2.apply(get_description)\n",
    "df['description_2'] = df['description_2'].replace('nan', 'Service')\n",
    "df['description'] = df['description'].replace('nan', 'Service')\n",
    "df['uom'] = df['uom'].replace('NAN', '-')\n",
    "df['cost'] = df['cost'].astype(float)\n",
    "df['qty'] = df['qty'].astype(float)\n",
    "\n",
    "# conditional\n",
    "a = df[df.equipment_name=='HONGYAN KINKAN430']\n",
    "b = df[df.equipment_name!='HONGYAN KINKAN430']\n",
    "a.requirement_type.replace('External', 'Internal', inplace=True)\n",
    "df = pd.concat([a, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade02d54-1a94-4668-9bd9-eda84699cd17",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Production.Timesheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "124a3af9-2849-44ef-96c2-456ac349bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract production.timesheet\n",
    "path_ts = '/Users/dickyaryanto/Documents/PT Sentosa Abadi Mining/Data/production timesheet'\n",
    "df2 = read_file(path_ts)\n",
    "\n",
    "df2.columns = ['_'.join(i.split()).lower() for i in df2.columns]\n",
    "df2 = df2[df2.date.dt.year >= 2023]\n",
    "# df2 = df2[df2['date']!=pd.to_datetime(str(pd.to_datetime(datetime.now())).split()[0])]\n",
    "df2['hm_realtime_start'] = df2['hm_realtime_start'].apply(lambda x: str(x).split('.')[0])\n",
    "df2['hm_realtime_end'] = df2['hm_realtime_end'].apply(lambda x: str(x).split('.')[0])\n",
    "\n",
    "def get_true_time(date, time):\n",
    "    time = str(time)\n",
    "    if len(time) == 2:\n",
    "        time = str(time) + ':00:00'\n",
    "    else:\n",
    "        time = '0' + str(time) + ':00:00'\n",
    "        \n",
    "    date = str(date).split()[0]\n",
    "    msg = date + ' ' + time\n",
    "\n",
    "    try:\n",
    "        a = pd.to_datetime(msg)\n",
    "    except:\n",
    "        msg = 'error'\n",
    "    \n",
    "    return msg\n",
    "\n",
    "df2['date_engine_start'] = df2.apply(lambda x: get_true_time(x['date'], x['hm_realtime_start']), axis=1)\n",
    "df2['date_engine_end'] = df2.apply(lambda x: get_true_time(x['date'], x['hm_realtime_end']), axis=1)\n",
    "\n",
    "# split data\n",
    "df2_err = df2[(df2['date_engine_start']=='error') & (df2['date_engine_end']=='error')]\n",
    "df2 = df2[(df2['date_engine_start']!='error') & (df2['date_engine_end']!='error')]\n",
    "\n",
    "df2['date_engine_start'] = pd.to_datetime(df2['date_engine_start'])\n",
    "df2['date_engine_end'] = pd.to_datetime(df2['date_engine_end'])\n",
    "\n",
    "# cleaning condition memungkinkan tidak akan digunakan bila data bersih\n",
    "df2_err['actual_engine'] = df2_err['hm_realtime_end'].astype(float) - df2_err['hm_realtime_start'].astype(float)\n",
    "def retext_time(x):\n",
    "    time = str(x)\n",
    "    if len(time) == 2:\n",
    "        time = str(time) + ':00:00'\n",
    "    else:\n",
    "        time = '0' + str(time) + ':00:00'\n",
    "    return time\n",
    "\n",
    "def get_time_from_err(x):\n",
    "    start = 7\n",
    "    end = start + x\n",
    "\n",
    "    start_time = retext_time(str(start))\n",
    "    end_time = retext_time(str(end).split('.')[0])\n",
    "\n",
    "    msg = {'start':start_time, 'end':end_time}\n",
    "    return msg\n",
    "\n",
    "df2_err['hm_realtime_end'] = df2_err['actual_engine'].apply(lambda x: get_time_from_err(x)['end'])\n",
    "df2_err['hm_realtime_start'] = df2_err['actual_engine'].apply(lambda x: get_time_from_err(x)['start'])\n",
    "\n",
    "df2_err['date_engine_start'] = df2_err['date'].apply(lambda x: str(x).split()[0]) + ' ' + df2_err['hm_realtime_start']\n",
    "df2_err['date_engine_end'] = df2_err['date'].apply(lambda x: str(x).split()[0]) + ' ' + df2_err['hm_realtime_end']\n",
    "\n",
    "df2_err['date_engine_start'] = pd.to_datetime(df2_err['date_engine_start'])\n",
    "\n",
    "_ = []\n",
    "for i in df2_err.index:\n",
    "    n = df2_err[df2_err.index==i]\n",
    "    try:\n",
    "        n['date_engine_end'] = pd.to_datetime(n['date_engine_end'])\n",
    "    except:\n",
    "        n['date_engine_end'] = 'error'\n",
    "    _.append(n)\n",
    "\n",
    "df2_err = pd.concat(_)\n",
    "error_actual_date = df2_err[df2_err.date_engine_end=='error']\n",
    "df2_err = df2_err[df2_err.date_engine_end!='error']\n",
    "\n",
    "df2 = pd.concat([df2, df2_err])\n",
    "\n",
    "df2['date_engine_end'] = pd.to_datetime(df2['date_engine_end'])\n",
    "df2['date_engine_start'] = pd.to_datetime(df2['date_engine_start'])\n",
    "df2['actual_engine'] = df2.date_engine_end - df2.date_engine_start\n",
    "df2['actual_engine'] = df2['actual_engine'].apply(timedelta_to_hour)\n",
    "df2 = df2[df2.state!='Draft']\n",
    "\n",
    "df2['component_line/out_weight'].fillna(0, inplace=True)\n",
    "df2['component_line/net_weight/voll'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a055452-f442-4106-b855-5cf408f9cd8a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Maintenance.Equipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ba67ee3-10b0-4457-b72e-58d6594c201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_eq = '/Users/dickyaryanto/Documents/PT Sentosa Abadi Mining/Data/maintenance equipment'\n",
    "tbl_equipment2 = read_file(path_eq)\n",
    "tbl_equipment2['equipment_code'] = tbl_equipment2.Name.apply(lambda x: str(x) + '/') + tbl_equipment2['Serial Number'].apply(lambda x: str(x))\n",
    "tbl_equipment2.columns = ['_'.join(i.lower().split()) for i in tbl_equipment2.columns.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e2117a-b712-4724-a0eb-e879d37710d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Purchase.Order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bad6ba-99a8-4c79-9f06-82243204230c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1. PO Node3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1239621a-92c8-4d83-8eb0-b48720c76393",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_po = '/Users/dickyaryanto/Documents/PT Sentosa Abadi Mining/Data/purchase order'\n",
    "po = read_file(path_po)\n",
    "\n",
    "po.columns = ['_'.join(i.lower().split()) for i in po.columns]\n",
    "po['total'] = po['order_lines/quantity'] * po['order_lines/unit_price']\n",
    "po = po.ffill()\n",
    "po.drop(columns=['source_document','purchase_requests','order_lines/description'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e2a7f0-7590-4bd7-9d2a-35233233fd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab06f9-7432-41d6-a8ae-54b47b8ed6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5843ebf4-f83c-4448-9f99-a0655d05cb12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c13597b-edca-4475-b457-d0d530cded34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64765a4-f0ba-4ecd-bca5-077c018d8fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87c4567-5369-4451-af5d-d6dd5d4a2982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9878af1-2048-4812-8ea8-6fd9d0d9a85b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2. PO Selain Dari Node3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5da5f928-254a-4cff-a0a5-5a06cb81c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract data PO diluar Node3 ambil dari Google Drive \n",
    "url = \"https://docs.google.com/spreadsheets/d/1Ay0TNz8yPhdNzr4KhGmNy1QENGJS6B-Z/export?format.xlsx\"\n",
    "try:\n",
    "    os.remove('po_sam.xlsx')\n",
    "except:\n",
    "    None\n",
    "    \n",
    "output_filename = \"po_sam.xlsx\"\n",
    "\n",
    "# get the data from spreadsheet\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(output_filename, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "# transformasi nama columns\n",
    "po_sam_rekap = pd.read_excel('po_sam.xlsx', sheet_name='rekap')\n",
    "po_sam_rekap.columns = ['_'.join(i.lower().split()) for i in po_sam_rekap.columns]\n",
    "\n",
    "po_sam_detail = pd.read_excel('po_sam.xlsx', sheet_name='detail')\n",
    "po_sam_detail.columns = ['_'.join(i.lower().split()) for i in po_sam_detail.columns]\n",
    "\n",
    "# merge\n",
    "po_sam = po_sam_rekap.merge(po_sam_detail[['nopo','nodt','tglterima']], on='nopo')\n",
    "po_sam = po_sam[['nopo','nodt','tglterima','description','qty','ppn']]\n",
    "po_sam.columns = ['no_po','name','broken','description','qty','cost']\n",
    "\n",
    "def get_same_text(text1):\n",
    "    n = tbl_equipment2.copy()\n",
    "    n['similairity'] = n.name.apply(lambda x: similairty_sentence(text1, x))\n",
    "    n.sort_values('similairity', ascending=False, inplace=True)\n",
    "    n = n.head(1)\n",
    "\n",
    "    score = n['similairity'].unique().tolist()[0]\n",
    "    if score >= 0.9:\n",
    "        try:\n",
    "            cat_eq = n['equipment_category'].unique().tolist()[0]\n",
    "            eq_model = n['equipment_model'].unique().tolist()[0]\n",
    "            name = n['name'].unique().tolist()[0]\n",
    "            id = n['serial_number'].unique().tolist()[0]\n",
    "            msg = {'cat_eq':[cat_eq],'eq_model':[eq_model],'name':[name],'id':[id]}\n",
    "        except:\n",
    "            msg = {'cat_eq':[np.NaN],'eq_model':[np.NaN],'name':[text1],'id':[np.NaN]}\n",
    "    else:\n",
    "        msg = {'cat_eq':[np.NaN],'eq_model':[np.NaN],'name':[text1],'id':[np.NaN]}\n",
    "        \n",
    "    return msg\n",
    "\n",
    "def get_same_text_category_maintenance(text1):\n",
    "    n = df.copy()\n",
    "    n = n[['category_maintenance','description']]\n",
    "    n.drop_duplicates(inplace=True)\n",
    "    n['similairity'] = n.description.apply(lambda x: similairty_sentence(text1, x))\n",
    "    n.sort_values('similairity', ascending=False, inplace=True)\n",
    "    n = n.head(1)\n",
    "\n",
    "    score = n['similairity'].unique().tolist()[0]\n",
    "    if score >= 0.8:\n",
    "        try:\n",
    "            msg = n['category_maintenance'].unique().tolist()[0]\n",
    "        except:\n",
    "            msg = np.NaN\n",
    "    else:\n",
    "        msg = np.NaN\n",
    "        \n",
    "    return msg\n",
    "\n",
    "po_sam['category_equipment'] = po_sam.name.apply(lambda x: get_same_text(x)['cat_eq'][0])\n",
    "po_sam['equipment_name'] = po_sam.name.apply(lambda x: get_same_text(x)['eq_model'][0])\n",
    "po_sam['id'] = po_sam.name.apply(lambda x: get_same_text(x)['id'][0])\n",
    "po_sam['name'] = po_sam.name.apply(lambda x: get_same_text(x)['name'][0])\n",
    "po_sam.fillna('', inplace=True)\n",
    "po_sam['equipment_code'] = po_sam.name + '/' + po_sam['id']\n",
    "po_sam['category_maintenance'] = po_sam.description.apply(lambda x: get_same_text_category_maintenance(x))\n",
    "po_sam.fillna('HMSI', inplace=True)\n",
    "\n",
    "po_sam['company_code'] = po_sam.no_po.apply(lambda x: str(x).split('/')[1])\n",
    "\n",
    "po_sam['company'] = po_sam['company_code'].apply(lambda x: 'PT. SENTOSA ABADI MINING' if x == 'SAM' else 'Unknown')\n",
    "\n",
    "po_sam = po_sam[['company','broken','category_equipment','equipment_name','equipment_code','name','category_maintenance','description','qty','cost']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4e5324-6792-4058-a68a-854f9566934b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Standar Pengukuran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe0162cf-f459-4a8d-857b-53a9859e70d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_standar_ukur = '/Users/dickyaryanto/Documents/PT Sentosa Abadi Mining/Data/standar ukur'\n",
    "\n",
    "tbl_jarak = read_file(path_standar_ukur, 'tbl jarak move type')\n",
    "tbl_kapasitas = read_file(path_standar_ukur, 'tbl kapasitas dt')\n",
    "tbl_waktu = read_file(path_standar_ukur, 'tbl waktu move type')\n",
    "tbl_periodical = read_file(path_standar_ukur, 'tbl periodical unit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770266d1-1925-45b6-9bb0-bb1510027702",
   "metadata": {},
   "source": [
    "## Produksi Actual Site"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f49e575-305b-4836-9376-04281839c50e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1. Absen Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae259b18-4472-4f45-a286-f5149ce089a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://docs.google.com/spreadsheets/d/1CDBo-9hz0-Vc7e-hgjG1qdIZ07-PEdLlMatzssJhTJU/export?format.xlsx\"\n",
    "# try:\n",
    "#     os.remove('absen_driver.xlsx')\n",
    "# except:\n",
    "#     None\n",
    "    \n",
    "# output_filename = 'absen_driver.xlsx'\n",
    "\n",
    "# # get the data from spreadsheet\n",
    "# response = requests.get(url)\n",
    "# if response.status_code == 200:\n",
    "#     with open(output_filename, \"wb\") as f:\n",
    "#         f.write(response.content)\n",
    "\n",
    "# # read data absen driver dari tbl produksi actual site\n",
    "# absen_driver = pd.read_excel('absen_driver.xlsx', sheet_name='Absen Driver')\n",
    "# absen_driver = absen_driver[1:]\n",
    "# absen_driver.columns = ['_'.join(i.lower().split()) for i in absen_driver.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da112968-00b1-4983-b026-25c063f8519a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2. Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdf0fcb0-0a60-484f-935c-08f96803bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://docs.google.com/spreadsheets/d/12_BTs8ftDwcp0DCva7wTZzLuzaE9nkKrgJ_onoqMbDM/export?format.xlsx\"\n",
    "# try:\n",
    "#     os.remove('grade_report.xlsx')\n",
    "# except:\n",
    "#     None\n",
    "    \n",
    "# output_filename = 'grade_report.xlsx'\n",
    "\n",
    "# # get the data from spreadsheet\n",
    "# response = requests.get(url)\n",
    "# if response.status_code == 200:\n",
    "#     with open(output_filename, \"wb\") as f:\n",
    "#         f.write(response.content)\n",
    "\n",
    "# # read data grade\n",
    "# df_grade = pd.read_excel('grade_report.xlsx', sheet_name='Laporan Grade', names=['timestamps','date','dome id',\n",
    "#                                                                                          'tonase','ni','fe','sio2/mgo','nan','kontrak','standar_grade'])\n",
    "# # read grade\n",
    "# grade = df_grade[1:]\n",
    "# grade = grade[['timestamps','date','dome id','tonase','ni','fe','sio2/mgo']]\n",
    "\n",
    "# # read standar grade\n",
    "# tbl_grade = df_grade[1:]\n",
    "# tbl_grade = tbl_grade[['kontrak','standar_grade']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd34a66-05fc-491d-b661-c48cfcf153cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3. Accdient Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0630b5d1-85b9-4449-b03f-5a19b63713d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://docs.google.com/spreadsheets/d/19y9xZ3L3AMYGDZOVG_6Q5hNX7HFQSW__tf6YXX_Ojgk/export?format.xlsx\"\n",
    "# try:\n",
    "#     os.remove('accident_rate.xlsx')\n",
    "# except:\n",
    "#     None\n",
    "    \n",
    "# output_filename = 'accident_rate.xlsx'\n",
    "\n",
    "# # get the data from spreadsheet\n",
    "# response = requests.get(url)\n",
    "# if response.status_code == 200:\n",
    "#     with open(output_filename, \"wb\") as f:\n",
    "#         f.write(response.content)\n",
    "\n",
    "# # read data absen driver dari tbl produksi actual site\n",
    "# accident = pd.read_excel('accident_rate.xlsx')\n",
    "# accident = accident[1:]\n",
    "# accident.columns = ['timestamps','id','dol','ba','kat_kecelakaan','tempat',\n",
    "#                     'name','departemen','emp','umur','estimate','keterangan']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f740dff-4f04-487f-9f3e-c27d21802356",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **EDA : Exploratory Data Analyst**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2225dc-26fe-4ffd-bcb9-9de4087869e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Task 1 : DASHBOARD\n",
    "\n",
    "Berapa waktu rata-rata yang dibutuhkan untuk team Workshop memperbaiki setiap request dari setiap crew produksi/transportasi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a17087b3-585b-46c5-ada5-290fdbca2cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = df.copy()\n",
    "t1['t_broken_done'] = t1.done - t1.broken\n",
    "t1['t_schedule_done'] = t1.done - t1.schedule\n",
    "t1['requirement_type'].replace('', 'Internal', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfc48284-48ea-4a56-a54b-50f24aab2f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_in = t1[t1.requirement_type=='Internal']\n",
    "t1_ex = t1[t1.requirement_type=='External']\n",
    "t1_ex['spk'] = t1_ex['spk'].apply(lambda x: str(x))\n",
    "t1_ex.drop(columns=['description','qty','uom','description_2','cost'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48b4ff56-aaf6-45c5-b647-5aad1c8bcae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "po_spk = po[po.no_spk!=False]\n",
    "po_spk['no_spk'] = po_spk['no_spk'].apply(lambda x: str(str(x).split('/')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2175068-fe58-465f-8908-94b670214212",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_ex = t1_ex.merge(po_spk[['no_spk', 'order_lines/product', 'order_lines/quantity', 'order_lines/unit_of_measure','total']], how='left', left_on='spk', right_on='no_spk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf5b7d6f-ca05-4b03-93c6-181378144543",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_ex = t1_ex.rename(columns={\n",
    "    'order_lines/product':'description',\n",
    "    'order_lines/quantity':'qty',\n",
    "    'order_lines/unit_of_measure':'uom',\n",
    "    'total':'cost'\n",
    "})\n",
    "\n",
    "t1_ex['uom'] = t1_ex['uom'].apply(lambda x: str(x).upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4b1b6ba-c2f7-4c2a-9399-92142b574268",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_ex['description_2'] = t1_ex.description.apply(get_description)\n",
    "t1_ex['description_2'].fillna('Service', inplace=True)\n",
    "t1_ex = t1_ex[t1_in.columns]\n",
    "t1_ex['cost'].fillna(0, inplace=True)\n",
    "t1_ex['cost'] = t1_ex.cost / t1_ex.qty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a044972e-d1f1-4785-914e-c0e3e9254e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.concat([t1_in, t1_ex])\n",
    "t1 = t1.sort_values('spk', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f775c63-baf8-4287-ac4e-42d8b71af085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to transform timedelat to minute\n",
    "def timedelta_to_minute(timedelta_str):\n",
    "    # Konversi timedelta string ke timedelta object\n",
    "    timedelta_obj = pd.to_timedelta(timedelta_str)\n",
    "    \n",
    "    # Hitung total detik dalam timedelta\n",
    "    total_seconds = timedelta_obj.total_seconds()\n",
    "    \n",
    "    # Konversi total detik ke jam\n",
    "    total_minute = total_seconds / 60\n",
    "    \n",
    "    return total_minute\n",
    "\n",
    "t1['t_broken_done'] = t1['t_broken_done'].apply(timedelta_to_minute)\n",
    "t1['t_schedule_done'] = t1['t_schedule_done'].apply(timedelta_to_minute)\n",
    "t1['t_broken_done'].fillna(0, inplace=True)\n",
    "t1['t_schedule_done'].fillna(0, inplace=True)\n",
    "t1 = t1[t1.stage != 'Cancel']\n",
    "t1['cost'] = t1.cost * t1.qty\n",
    "\n",
    "def get_time(x):\n",
    "    hours = int(x // 60)\n",
    "    remaining_minutes = int(x % 60)\n",
    "    formated_time = f\"{hours} Hour {remaining_minutes} Minute\"\n",
    "    formated_time = pd.to_timedelta(formatted_time)\n",
    "    return formated_time\n",
    "\n",
    "t1['number'] = 1\n",
    "t1['category_maintenance'].replace('TRYE', 'TYRE', inplace=True)\n",
    "t1['name'] = t1.equipment_code.apply(lambda x: str(x).split('/')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d65d50b2-91f0-4b0f-b668-63650412a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1['equipment_name'] = t1['equipment_name'].apply(lambda x: ' '.join(str(x).split()))\n",
    "\n",
    "def retext_equipment_name_t1(x):\n",
    "    if x in ['SAKAI SAKAI SV 525 D']:\n",
    "        msg = 'SAKAI SV'\n",
    "    else:\n",
    "        x = ' '.join(x.split()[:2])\n",
    "        if x in ['KOMATSU PC200-8M1','KOMATSU PC200-10/S21','KOMATSU PC200-8M0','KOMATSU PC200-8']:\n",
    "            msg = 'KOMATSU PC200'\n",
    "        elif x in ['HINO WU352R-HKMRJD8B','HINO WU352R-HKMRJD3L']:\n",
    "            msg = 'HINO WU352R'\n",
    "        elif x in ['KOBELCO SK200-10','KOBELCO SK330-14','KOBELCO SK']:\n",
    "            msg = 'KOBELCO SK'\n",
    "        elif x in ['KOMATSU PC300SE-8','KOMATSU PC300SE-8MO','KOMATSU PC300-8M0','KOMATSU PC300SE-8M0']:\n",
    "            msg = 'KOMATSU PC300'\n",
    "        elif x in ['KOMATSU PC400LCSE-8']:\n",
    "            msg = 'KOMATSU PC400'\n",
    "        elif x in ['KOMATSU D85ESS-2','KOMATSU D85E-SS-2']:\n",
    "            msg = 'KOMATSU D85'\n",
    "        elif x in ['KOMATSU D65P-12']:\n",
    "            msg = 'KOMATSU D65'\n",
    "        elif x in ['KOMATSU GD511A-1','KOMATSU GD535-5']:\n",
    "            msg = 'KOMATSU GD'\n",
    "        elif x in ['KOMATSU HM400-3R','KOMATSU HM400']:\n",
    "            msg = 'KOMATSU HM400'\n",
    "        elif x in ['KOMATSU PC500LC-10R']:\n",
    "            msg = 'KOMATSU PC500'\n",
    "        elif x in ['PAJERO SPORT','PAJERO']:\n",
    "            msg = 'PAJERO'\n",
    "        else:\n",
    "            msg = x.split('-')[0]\n",
    "    return msg\n",
    "\n",
    "t1['equipment_name'] = t1['equipment_name'].apply(lambda x: retext_equipment_name_t1(x))\n",
    "t1 = t1[t1.equipment_name!='NISSAN CWA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "991af8ed-32fc-48ad-8ed5-752a8cee2901",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.to_excel('./Report/task1.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65960017-d0ec-4085-a970-1dc246cbfef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_1 = t1.copy()\n",
    "t1_1['date_broken'] = pd.to_datetime(t1_1.broken).dt.date\n",
    "\n",
    "broken = t1_1[['broken','category_equipment','equipment_name','spk']]\n",
    "broken['date'] = broken.broken.dt.date\n",
    "broken = broken.drop_duplicates(subset='spk')\n",
    "broken = broken.groupby(['date','category_equipment','equipment_name'])[['spk']].count().reset_index().rename(columns={'spk':'values'})\n",
    "broken['status'] = 'Broken'\n",
    "\n",
    "done = t1_1[['done','category_equipment','equipment_name','spk']]\n",
    "done['date'] = done.done.dt.date\n",
    "done = done.drop_duplicates(subset='spk')\n",
    "done = done.groupby(['date','category_equipment','equipment_name'])[['spk']].count().reset_index().rename(columns={'spk':'values'})\n",
    "done['status'] = 'Done'\n",
    "\n",
    "t1_1 = pd.concat([broken, done])\n",
    "t1_1 = t1_1[pd.to_datetime(t1_1.date).dt.year >= 2023]\n",
    "t1_1 = t1_1.rename(columns={'date':'request'})\n",
    "t1_1.to_excel('./Report/task1_1.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedc8f4b-6b26-4636-bde6-5edf71cbb480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97311975-4585-499e-b2be-c6de0f3b71d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Task 2 : Dashboard\n",
    "\n",
    "KPI Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1827b753-c3a4-4156-b87d-b77328aea195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ukur PA masing-masing alat\n",
    "jam_operasional = df2[['company','project/name','production','move_type','name','date','date_engine_start','date_engine_end','equipment','component_line/net_weight/voll']]\n",
    "jam_operasional = jam_operasional.rename(columns={'actual_engine':'hm_engine_actual'})\n",
    "jam_operasional = jam_operasional.rename(columns={'component_line/net_weight/voll':'produksi'})\n",
    "jam_operasional['produksi'] = jam_operasional['produksi'] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e0499d8-46c3-4d34-9f33-65411bcc2083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_work_date(x):\n",
    "    x = str(x).split()[0]\n",
    "    \n",
    "    date_start = str(x).split()[0] + ' 07:00:00'\n",
    "    date_end = str(x).split()[0] + ' 17:00:00'\n",
    "    msg = {'start':date_start, 'end':date_end}\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c445cd8-b089-4ee6-bd8b-81873343d6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "jam_operasional['actual_start_date'] = jam_operasional.date.apply(lambda x: get_work_date(x)['start'])\n",
    "jam_operasional['actual_end_date'] = jam_operasional.date.apply(lambda x: get_work_date(x)['end'])\n",
    "\n",
    "jam_operasional['actual_start_date'] = pd.to_datetime(jam_operasional['actual_start_date'])\n",
    "jam_operasional['actual_end_date'] = pd.to_datetime(jam_operasional['actual_end_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ebbfdbc-fd67-481b-8364-0c801acd9e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_actual_work(actual_start, actual_end, engine_start, engine_end):\n",
    "    start = pd.DataFrame({'start_date':[actual_start, engine_start]})\n",
    "    end = pd.DataFrame({'end_date':[actual_end, engine_end]})\n",
    "\n",
    "    start = start[start.start_date==start.start_date.max()]\n",
    "    start = start.start_date.tolist()[0]\n",
    "\n",
    "    end = end[end.end_date==end.end_date.min()]\n",
    "    end = end.end_date.tolist()[0]\n",
    "\n",
    "    msg = end - start\n",
    "    msg = timedelta_to_hour(msg)\n",
    "    return msg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "816001c8-c90e-4923-ab78-c4ff0805779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jam_operasional['hm_engine_in_work_productivity'] = jam_operasional.apply(lambda x: get_real_actual_work(x.actual_start_date, x.actual_end_date, x.date_engine_start, x.date_engine_end), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae04ec9a-dfdb-4457-bacb-fc1715e0cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jam_operasional = jam_operasional.groupby(['company','project/name','production','move_type','name','date','equipment'])[['hm_engine_in_work_productivity','produksi']].sum().reset_index()\n",
    "jam_operasional = jam_operasional.reset_index().sort_values('index', ascending=False).drop(columns='index').reset_index(drop=True)\n",
    "jam_operasional['date'] = jam_operasional['date'].dt.date\n",
    "jam_operasional['date'] = jam_operasional['date'].apply(lambda x: str(x))\n",
    "jam_operasional = jam_operasional.rename(columns={'name':'spk_project'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00d26056-f880-452d-b00d-eb177fe1884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jam_stanby_true(x):\n",
    "    if x < 0:\n",
    "        msg = 0\n",
    "    else:\n",
    "        msg = x\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84e768d6-2a03-46de-8f75-28562b56b1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "jam_operasional['hm_engine_in_work_productivity'] = jam_operasional['hm_engine_in_work_productivity'].apply(get_jam_stanby_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd97a84f-e6e3-4f76-a6a2-2aad8520195a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 339/339 [00:14<00:00, 22.84it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "_ = []\n",
    "for i in tqdm(jam_operasional.equipment.unique().tolist()):\n",
    "    n = jam_operasional[jam_operasional.equipment==i]\n",
    "    n['date'] = pd.to_datetime(n['date']).dt.date\n",
    "    for y in n['date'].unique().tolist():\n",
    "        m = n[n['date']==y]\n",
    "\n",
    "        company = m['company'].unique().tolist()[0]\n",
    "        project = m['project/name'].unique().tolist()[0]\n",
    "        production = ';'.join(m['production'].tolist())\n",
    "        move_type = m['move_type'].unique().tolist()[0]\n",
    "        spk = ';'.join(m['spk_project'].tolist())\n",
    "        hm_engine = m['hm_engine_in_work_productivity'].sum()\n",
    "        produksi = m['produksi'].sum()\n",
    "        \n",
    "        try:\n",
    "            msg = pd.DataFrame({\n",
    "                'company':[company],\n",
    "                'project/name':[project],\n",
    "                'production':production,\n",
    "                'spk_project':spk,\n",
    "                'move_type':move_type,\n",
    "                'date':[y],\n",
    "                'equipment':[i],\n",
    "                'hm_engine_in_work_productivity':[hm_engine],\n",
    "                'produksi':[produksi]\n",
    "            })\n",
    "        except:\n",
    "            msg = pd.DataFrame({\n",
    "                'company':[company],\n",
    "                'project/name':[project],\n",
    "                'production':production,\n",
    "                'spk_project':spk,\n",
    "                'move_type':[move_type],\n",
    "                'date':[y],\n",
    "                'equipment':[i],\n",
    "                'hm_engine_in_work_productivity':[hm_engine],\n",
    "                'produksi':[produksi]\n",
    "            })\n",
    "\n",
    "        _.append(msg)\n",
    "            \n",
    "\n",
    "jam_operasional = pd.concat(_).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "718260a3-407c-406c-9443-10790bc0f308",
   "metadata": {},
   "outputs": [],
   "source": [
    "jam_breakdown = df[['stage','spk','category_equipment','equipment_name','equipment_code','broken','done']]\n",
    "jam_breakdown['name'] = jam_breakdown.equipment_code.apply(lambda x: str(x).split('/')[0])\n",
    "jam_breakdown = jam_breakdown[['stage', 'spk', 'category_equipment', 'equipment_name','equipment_code', 'name', 'broken', 'done']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75a7a959-1db1-498e-a3ab-92d89ab47154",
   "metadata": {},
   "outputs": [],
   "source": [
    "jam_breakdown = jam_breakdown.rename(columns={'spk':'spk_workshop'})\n",
    "jam_breakdown = jam_breakdown[jam_breakdown.stage!='Cancel']\n",
    "jam_breakdown = jam_breakdown[jam_breakdown.equipment_code != False]\n",
    "\n",
    "# fill jam done dengan waktu update apabila belum selesai diperbaiki\n",
    "from datetime import datetime\n",
    "def get_done_time(x, breakdown):\n",
    "    con = str(x)\n",
    "    if con == None or con == np.NaN or con == 'NaT':\n",
    "        msg = get_work_date(breakdown)['end']\n",
    "    else:\n",
    "        msg = x\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc86b192-1226-4ebd-988a-ff25a7fa653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jam_breakdown['done'] = jam_breakdown.apply(lambda x: get_done_time(x.done, x.broken), axis=1)\n",
    "jam_breakdown.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "edd75fe2-f704-4796-8c09-77253dad2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "jam_breakdown['actual_start_date'] = jam_breakdown['broken'].apply(lambda x: get_work_date(x)['start'])\n",
    "jam_breakdown['actual_end_date'] = jam_breakdown['broken'].apply(lambda x: get_work_date(x)['end'])\n",
    "jam_breakdown['actual_start_date'] = pd.to_datetime(jam_breakdown['actual_start_date'])\n",
    "jam_breakdown['actual_end_date'] = pd.to_datetime(jam_breakdown['actual_end_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11aa16a3-ba64-4825-be90-d7378171b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_actual_work_breakdown(actual_start, actual_end, breakdown, done, stage):\n",
    "    start = pd.DataFrame({'start_date':[actual_start, breakdown]})\n",
    "    end = pd.DataFrame({'end_date':[actual_end, done]})\n",
    "\n",
    "    start = start[start.start_date==start.start_date.max()]\n",
    "    start = start.start_date.tolist()[0]\n",
    "\n",
    "    if stage != 'DONE':\n",
    "        end = actual_end\n",
    "    else:\n",
    "        end = end[end.end_date==end.end_date.min()]\n",
    "        end = end.end_date.tolist()[0]\n",
    "\n",
    "    msg = end - start\n",
    "    msg = timedelta_to_hour(msg)\n",
    "    if msg < 0:\n",
    "        msg = 0\n",
    "    else:\n",
    "        None\n",
    "    return msg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bae2a4ac-6ef3-4d15-8a5f-bc01a3ad870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jam_breakdown['hm_maintenance'] = jam_breakdown.apply(lambda x: get_real_actual_work_breakdown(x.actual_start_date, x.actual_end_date, x.broken, x.done, x.stage), axis=1)\n",
    "jam_breakdown = jam_breakdown[jam_breakdown.broken.dt.year >= 2023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d990d1dd-9d69-40d5-b199-72d06591fa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 422/422 [00:18<00:00, 23.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "_ = []\n",
    "for i in tqdm(jam_breakdown.equipment_code.unique().tolist()):\n",
    "    n = jam_breakdown[jam_breakdown.equipment_code==i]\n",
    "    n['date'] = n.broken.dt.date\n",
    "    for y in n.date.unique().tolist():\n",
    "        m = n[n['date']==y]\n",
    "\n",
    "        stage = ';'.join(m['stage'].tolist())\n",
    "        spk = ';'.join(m.spk_workshop.tolist())\n",
    "        cat_eq = m['category_equipment'].unique().tolist()[0]\n",
    "        eq_name = m['equipment_name'].unique().tolist()[0]\n",
    "        eq_code = m['equipment_code'].unique().tolist()[0]\n",
    "        name = m['name'].unique().tolist()[0]\n",
    "        broken = ';'.join(m['broken'].apply(lambda x: str(x)).tolist())\n",
    "        done = ';'.join(m['done'].apply(lambda x: str(x)).tolist())\n",
    "        hm = m.hm_maintenance.sum()\n",
    "        \n",
    "        msg = pd.DataFrame({\n",
    "            'stage':[stage],\n",
    "            'spk_workshop':[spk],\n",
    "            'category_equipment':[cat_eq],\n",
    "            'equipment_name':[eq_name],\n",
    "            'name':[name],\n",
    "            'equipment_code':[eq_code],\n",
    "            'date':[y],\n",
    "            'broken':[broken],\n",
    "            'done':[done],\n",
    "            'hm_maintenance':[hm]\n",
    "        })\n",
    "        _.append(msg)\n",
    "\n",
    "jam_breakdown = pd.concat(_).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4b9ba51-852c-41dd-879b-fa231e4c47e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_scale(x):\n",
    "    if x > 10:\n",
    "        msg = 10\n",
    "    else:\n",
    "        msg = x\n",
    "    return msg\n",
    "\n",
    "jam_breakdown['hm_maintenance'] = jam_breakdown['hm_maintenance'].apply(in_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "340714f4-aec1-4522-9b96-8bc47c4bf20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(jam, equipment):\n",
    "    jam = str(jam)\n",
    "    eq = str(equipment)\n",
    "    msg = '#' + jam + '#' + eq\n",
    "    return msg\n",
    "\n",
    "jam_operasional['id'] = jam_operasional.apply(lambda x: get_id(x['date'], x['equipment']), axis=1)\n",
    "jam_breakdown['id'] = jam_breakdown.apply(lambda x: get_id(x['date'], x['equipment_code']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e9ec33e-2ce7-475c-a097-94d41427036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jam_operasional = jam_operasional.rename(columns={'hm_engine_in_work_productivity':'hm_engine_actual'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "262ee34a-1ef1-4b39-a5bf-0de6b9157ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = pd.merge(jam_operasional[['id','company','project/name','production','move_type','spk_project','hm_engine_actual','produksi']], jam_breakdown[['id','stage','spk_workshop','hm_maintenance']], how='outer', on='id')\n",
    "t2['date'] = t2['id'].apply(lambda x: str(x).split('#')[1])\n",
    "t2['equipment_code'] = t2['id'].apply(lambda x: str(x).split('#')[-1])\n",
    "t2 = t2.merge(jam_breakdown[['category_equipment','equipment_name','name','equipment_code']], on='equipment_code', how='left')\n",
    "t2['day'] = pd.to_datetime(t2.date).dt.day\n",
    "t2['month'] = pd.to_datetime(t2.date).dt.month\n",
    "t2['year'] = pd.to_datetime(t2.date).dt.year\n",
    "t2 = t2.sort_values(['year','month','day'], ascending=False)\n",
    "t2.reset_index(drop=True, inplace=True)\n",
    "t2.drop(columns=['day','month','year'], inplace=True)\n",
    "t2['hm_engine_actual'].fillna(0, inplace=True)\n",
    "t2 = t2.rename(columns={'hm_engine_actual':'jam_produktivitas','hm_maintenance':'jam_breakdown'})\n",
    "t2['jam_breakdown'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5ea29a9-2944-4a41-98cd-a93e871e325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jam_stanby_true(x):\n",
    "    if x < 0:\n",
    "        msg = 0\n",
    "    else:\n",
    "        msg = x\n",
    "    return msg\n",
    "\n",
    "t2['jam_standby'] = t2.apply(lambda x: get_jam_stanby_true(10 - (x.jam_produktivitas + x.jam_breakdown)), axis=1)\n",
    "t2['spk_project'].fillna('-', inplace=True)\n",
    "t2['move_type'].fillna('-', inplace=True)\n",
    "t2['spk_workshop'].fillna('-', inplace=True)\n",
    "t2['project/name'].fillna('-', inplace=True)\n",
    "t2['company'].fillna('-', inplace=True)\n",
    "t2['project/name'] = t2['project/name'].apply(lambda x: str(x))\n",
    "t2['produksi'].fillna(0, inplace=True)\n",
    "t2['production'].fillna('-', inplace=True)\n",
    "t2['stage'].fillna('-', inplace=True)\n",
    "t2['category_equipment'].fillna('Tidak Diketahui', inplace=True)\n",
    "t2['equipment_name'].fillna('Tidak Diketahui', inplace=True)\n",
    "t2['name'].fillna('Tidak Diketahui', inplace=True)\n",
    "t2.drop(columns='id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "68e41a4d-fa86-4462-9033-f4e28570c58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Tentukan tanggal awal (1 Januari 2023)\n",
    "start_date = datetime(2023, 1, 1)\n",
    "\n",
    "# Tentukan tanggal hari ini\n",
    "today = datetime.today()\n",
    "\n",
    "# Buat list untuk menyimpan rentang tanggal\n",
    "date_range = []\n",
    "\n",
    "# Hitung jumlah hari dari tanggal awal hingga hari ini\n",
    "delta = today - start_date\n",
    "\n",
    "# Tambahkan setiap tanggal dalam rentang tersebut ke dalam list\n",
    "for i in range(delta.days + 1):\n",
    "    date = start_date + timedelta(days=i)\n",
    "    date_range.append(date)\n",
    "\n",
    "date = pd.DataFrame({'date':date_range})\n",
    "date['date'] = date['date'].apply(lambda x: str(x).split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "97603927-618c-4980-96c4-6514fcf68903",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = t2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e859189-81a2-4026-8ee9-21f97081e1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 432/432 [00:02<00:00, 166.07it/s]\n"
     ]
    }
   ],
   "source": [
    "kpi = []\n",
    "for i in tqdm(t2.equipment_code.unique().tolist()):\n",
    "    n = t2[t2.equipment_code==i]\n",
    "\n",
    "    cat_eq = n.category_equipment.unique().tolist()[0]\n",
    "    eq_code = n.equipment_code.unique().tolist()[0]\n",
    "    eq_name = n.equipment_name.unique().tolist()[0]\n",
    "    name = n.name.unique().tolist()[0]\n",
    "    \n",
    "    n = date.merge(n, on='date', how='left')\n",
    "    n['company'].fillna('-', inplace=True)\n",
    "    n['project/name'].fillna('-', inplace=True)\n",
    "    n['spk_project'].fillna('-', inplace=True)\n",
    "    n['spk_workshop'].fillna('-', inplace=True)\n",
    "    n['move_type'].fillna('-', inplace=True)\n",
    "    n['stage'].fillna('-', inplace=True)\n",
    "    n['production'].fillna('-', inplace=True)\n",
    "    n['category_equipment'].fillna(cat_eq, inplace=True)\n",
    "    n['equipment_name'].fillna(eq_name, inplace=True)\n",
    "    n['name'].fillna(name, inplace=True)\n",
    "    n['equipment_code'].fillna(eq_code, inplace=True)\n",
    "    n['jam_produktivitas'].fillna(0, inplace=True)\n",
    "    n['jam_breakdown'].fillna(0, inplace=True)\n",
    "    n['produksi'].fillna(0, inplace=True)\n",
    "    n['jam_standby'] = n.apply(lambda x: get_jam_stanby_true(10 - (x.jam_produktivitas + x.jam_breakdown)), axis=1)\n",
    "    kpi.append(n)\n",
    "\n",
    "# gabungkan data\n",
    "kpi = pd.concat(kpi)\n",
    "kpi['category_equipment'].replace('TidakDiketahui', 'Tidak Diketahui', inplace=True)\n",
    "kpi.drop_duplicates(inplace=True)\n",
    "\n",
    "# merge dengan data standar jarak tempuh move type\n",
    "kpi = kpi.merge(tbl_jarak, on='move_type', how='left').rename(columns={'jarak':'standar_jarak'})\n",
    "kpi['standar_jarak'].fillna(0, inplace=True)\n",
    "\n",
    "# merge dengna data standar maximal muatan dt\n",
    "kpi = kpi.merge(tbl_kapasitas[['equipment_name','kapasitas_maximal']], on='equipment_name', how='left')\n",
    "kpi['kapasitas_maximal'].fillna(0, inplace=True)\n",
    "\n",
    "kpi = kpi[['date','company','project/name','production','move_type','spk_project','spk_workshop','stage','category_equipment','equipment_name','name','equipment_code','standar_jarak','jam_produktivitas','jam_breakdown','jam_standby','kapasitas_maximal','produksi']]\n",
    "\n",
    "kpi['retase'] = kpi.produksi / kpi.kapasitas_maximal\n",
    "kpi['retase'].replace(np.inf, 0, inplace=True)\n",
    "kpi['total_jarak_tempuh'] = kpi.retase * kpi.standar_jarak\n",
    "kpi.fillna(0, inplace=True)\n",
    "kpi = kpi[kpi.equipment_name!='NISSAN CWA 260 X']\n",
    "\n",
    "kpi_ = kpi[kpi.category_equipment!='HEAVY EQUIPMENT']\n",
    "kpi__ = kpi[kpi.category_equipment=='HEAVY EQUIPMENT']\n",
    "\n",
    "def rename_heavy_equipment(x):\n",
    "    if x == 'SAKAI SAKAI SV 525 D':\n",
    "        msg = 'SAKAI'\n",
    "    elif x == 'KOMATSU LOADER WA 380-3':\n",
    "        msg = 'KOMATSU LOADER'\n",
    "    else:\n",
    "        fn = x.split()[0]\n",
    "        bn = ' '.join(x.split()[1:])[:2]\n",
    "        msg = fn + ' ' + bn\n",
    "    return msg \n",
    "\n",
    "kpi__['equipment_name'] = kpi__['equipment_name'].apply(rename_heavy_equipment)\n",
    "kpi = pd.concat([kpi_, kpi__])\n",
    "\n",
    "kpi = kpi.merge(tbl_waktu, on='move_type', how='left')\n",
    "kpi['waktu'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731daefe-4ed4-44dd-ab52-617bf3e38ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a996bde8-e1c5-4ceb-ac56-47dcbda2ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retext_jam_produktivitas(work, produksi, retase, waktu):\n",
    "    if work == 0 and produksi != 0:\n",
    "        msg = retase * waktu\n",
    "    else:\n",
    "        msg = work\n",
    "    return msg\n",
    "\n",
    "list_index = kpi[(kpi.jam_produktivitas == 0) & (kpi.produksi!=0)].index.tolist()\n",
    "\n",
    "kpi['jam_produktivitas'] = kpi.apply(lambda x: retext_jam_produktivitas(x.jam_produktivitas, x.produksi, x.retase, x.waktu), axis=1)\n",
    "\n",
    "def repair_jam(i, work, bd, s):\n",
    "    if i in list_index:\n",
    "        if work > 10:\n",
    "            work = 10 - bd\n",
    "            if work < 0:\n",
    "                work = 0\n",
    "        else:\n",
    "            work = work\n",
    "            if work < 0:\n",
    "                work = 0\n",
    "        \n",
    "        s = 10 - (work + bd)\n",
    "        msg = [work, bd, s]\n",
    "    else:\n",
    "        msg = [work, bd, s]\n",
    "    return msg\n",
    "\n",
    "kpi['retase'] = np.round(kpi['retase'])\n",
    "kpi['jam_produktivitas'] = kpi.reset_index().apply(lambda x: repair_jam(x['index'], x.jam_produktivitas, x.jam_breakdown, x.jam_standby)[0], axis=1)\n",
    "kpi['jam_breakdown'] = kpi.reset_index().apply(lambda x: repair_jam(x['index'], x.jam_produktivitas, x.jam_breakdown, x.jam_standby)[1], axis=1)\n",
    "kpi['jam_standby'] = kpi.reset_index().apply(lambda x: repair_jam(x['index'], x.jam_produktivitas, x.jam_breakdown, x.jam_standby)[2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c0357a-66ac-4045-9ff4-bb46cb8db06e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ccbcb31d-b406-4b49-a0a6-4cef28a0003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi.to_excel('./Report/task2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3c2e1b88-787e-4570-9ccd-042b5bec9406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ukur PA masing-masing alat\n",
    "jam_operasional = df2[['project/name','production','move_type','name','date','date_engine_start','date_engine_end','equipment','component_line/in_weight','component_line/out_weight','component_line/net_weight/voll']]\n",
    "jam_operasional = jam_operasional.rename(columns={'actual_engine':'hm_engine_actual'})\n",
    "jam_operasional = jam_operasional.rename(columns={'component_line/net_weight/voll':'produksi'})\n",
    "jam_operasional['produksi'] = jam_operasional['produksi'] / 1000\n",
    "\n",
    "jam_operasional = jam_operasional.rename(columns={\n",
    "    'component_line/in_weight':'in_weight',\n",
    "    'component_line/out_weight':'out_weight'\n",
    "})\n",
    "\n",
    "jam_operasional['in_weight'] = jam_operasional['in_weight'] / 1000\n",
    "jam_operasional['out_weight'] = jam_operasional['out_weight'] / 1000\n",
    "\n",
    "def get_work_date(x):\n",
    "    x = str(x).split()[0]\n",
    "    \n",
    "    date_start = str(x).split()[0] + ' 07:00:00'\n",
    "    date_end = str(x).split()[0] + ' 17:00:00'\n",
    "    msg = {'start':date_start, 'end':date_end}\n",
    "    return msg\n",
    "\n",
    "jam_operasional['actual_start_date'] = jam_operasional.date.apply(lambda x: get_work_date(x)['start'])\n",
    "jam_operasional['actual_end_date'] = jam_operasional.date.apply(lambda x: get_work_date(x)['end'])\n",
    "\n",
    "jam_operasional['actual_start_date'] = pd.to_datetime(jam_operasional['actual_start_date'])\n",
    "jam_operasional['actual_end_date'] = pd.to_datetime(jam_operasional['actual_end_date'])\n",
    "\n",
    "def get_real_actual_work(actual_start, actual_end, engine_start, engine_end):\n",
    "    start = pd.DataFrame({'start_date':[actual_start, engine_start]})\n",
    "    end = pd.DataFrame({'end_date':[actual_end, engine_end]})\n",
    "\n",
    "    start = start[start.start_date==start.start_date.max()]\n",
    "    start = start.start_date.tolist()[0]\n",
    "\n",
    "    end = end[end.end_date==end.end_date.min()]\n",
    "    end = end.end_date.tolist()[0]\n",
    "\n",
    "    msg = end - start\n",
    "    msg = timedelta_to_hour(msg)\n",
    "    return msg \n",
    "\n",
    "jam_operasional['hm_engine_in_work_productivity'] = jam_operasional.apply(lambda x: get_real_actual_work(x.actual_start_date, x.actual_end_date, x.date_engine_start, x.date_engine_end), axis=1)\n",
    "\n",
    "# jam_operasional = df2.groupby(['project/name','name','date','equipment'])[['hm_engine_actual']].sum().reset_index()\n",
    "jam_operasional = jam_operasional.groupby(['project/name','production','move_type','name','date','equipment'])[['hm_engine_in_work_productivity','in_weight','out_weight','produksi']].sum().reset_index()\n",
    "jam_operasional = jam_operasional.reset_index().sort_values('index', ascending=False).drop(columns='index').reset_index(drop=True)\n",
    "jam_operasional['date'] = jam_operasional['date'].dt.date\n",
    "jam_operasional['date'] = jam_operasional['date'].apply(lambda x: str(x))\n",
    "jam_operasional = jam_operasional.rename(columns={'name':'spk_project'})\n",
    "\n",
    "def get_jam_stanby_true(x):\n",
    "    if x < 0:\n",
    "        msg = 0\n",
    "    else:\n",
    "        msg = x\n",
    "    return msg\n",
    "\n",
    "jam_operasional['hm_engine_in_work_productivity'] = jam_operasional['hm_engine_in_work_productivity'].apply(get_jam_stanby_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "142557ed-a74d-4a88-a1e3-12595f96b57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_1 = jam_operasional.copy()\n",
    "t2_1 = t2_1.merge(df[['category_equipment','equipment_name','equipment_code']].drop_duplicates(), left_on='equipment', right_on='equipment_code', how='left').drop(columns='equipment')\n",
    "t2_1['name'] = t2_1.equipment_code.apply(lambda x: str(x).split('/')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0ec338a-f439-487f-9c2b-e772c0af08cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_1 = t2_1.groupby(['date','spk_project','project/name','production','move_type','category_equipment','equipment_name','name'])[['hm_engine_in_work_productivity','in_weight','out_weight','produksi']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4f3c972c-a18f-4595-9b96-672e524d748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_1.to_excel('./Report/task2_1.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a613d178-ab6b-437d-872b-4490b5bbccbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fca92055-e130-4945-a4dc-c11710bb62de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Task 3 : DASHBOARD\n",
    "\n",
    "Buat perbandingan antara Biaya terhadap hasil produksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a218e9a-7b50-4c66-a50b-5d0d95b940e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = df2.copy()\n",
    "t3 = t3[t3.production=='Hauling Ore']\n",
    "target = ['HINO ZS','HINO ZY','HONGYAN KINKAN430']\n",
    "equipment = df[df.equipment_name.isin(target)==True][['category_equipment','equipment_name','equipment_code']].drop_duplicates()\n",
    "equipment['equipment_detail'] = equipment.equipment_code.apply(lambda x: str(x).split('/')[0])\n",
    "t3 = t3.merge(equipment, left_on='equipment', right_on='equipment_code', how='left')\n",
    "t3 = t3[t3.equipment_name.isin(target)]\n",
    "t3['produksi'] = t3['component_line/in_weight'] - t3['component_line/out_weight']\n",
    "\n",
    "t3 = t3[['project/name','project','name','date','move_type','hm_engine_actual','production','employee','category_equipment','equipment_name','equipment_code','equipment_detail','component_line/in_weight','component_line/out_weight','produksi','state']]\n",
    "t3.columns = [i.split('/')[-1] for i in t3.columns]\n",
    "\n",
    "# group data produksi harian \n",
    "t3 = t3.groupby(['date','project','move_type','equipment_name','equipment_detail'])[['in_weight','out_weight','produksi']].sum().reset_index()\n",
    "t3['date'] = t3['date'].dt.date\n",
    "t3['date'] = t3['date'].astype(str)\n",
    "\n",
    "# klasifikasi status dari tujuan produksi berdasarkan moving type\n",
    "def get_produksi_status(x):\n",
    "    x = str(x)\n",
    "    con = x.split('- ')[-1]\n",
    "    if con == 'KM 7':\n",
    "        msg = 'Deposit'\n",
    "    else:\n",
    "        msg = 'Sell'\n",
    "    return msg\n",
    "\n",
    "t3['produksi_status'] = t3['move_type'].apply(lambda x: get_produksi_status(x))\n",
    "\n",
    "# group data biaya harian\n",
    "cost_t1 = t1.copy()\n",
    "cost_t1 = cost_t1[['broken','equipment_name','name','cost']]\n",
    "cost_t1['broken'] = cost_t1['broken'].dt.date\n",
    "cost_t1 = cost_t1.groupby(['broken','equipment_name','name'])[['cost']].sum().reset_index()\n",
    "cost_t1.columns = ['date','equipment_name','equipment_detail','cost']\n",
    "cost_t1['date'] = cost_t1['date'].astype(str)\n",
    "cost_t1 = cost_t1[cost_t1.equipment_name.isin(t3.equipment_name.unique().tolist())]\n",
    "\n",
    "# merge kedua data\n",
    "t3['id'] = t3.date +'#'+ t3.equipment_name +'#'+ t3.equipment_detail\n",
    "cost_t1['id'] = cost_t1.date +'#'+ cost_t1.equipment_name +'#'+ cost_t1.equipment_detail\n",
    "t3 = t3.merge(cost_t1[['id','cost']], on='id', how='outer')\n",
    "t3 = t3[['id','project','move_type','produksi_status','in_weight','out_weight','produksi','cost']]\n",
    "t3['date'] = t3['id'].apply(lambda x: str(x).split('#')[0])\n",
    "t3['equipment_name'] = t3['id'].apply(lambda x: str(x).split('#')[1])\n",
    "t3['equipment_detail'] = t3['id'].apply(lambda x: str(x).split('#')[-1])\n",
    "t3.drop(columns='id', inplace=True)\n",
    "\n",
    "t3 = t3[['date','project','move_type','produksi_status','equipment_name','equipment_detail','in_weight','out_weight','produksi','cost']]\n",
    "\n",
    "# cleaning data\n",
    "t3['cost'].fillna(0, inplace=True)\n",
    "t3['in_weight'].fillna(0, inplace=True)\n",
    "t3['out_weight'].fillna(0, inplace=True)\n",
    "t3['produksi'].fillna(0, inplace=True)\n",
    "t3['project'].fillna('Breakdown', inplace=True)\n",
    "t3['move_type'].fillna('Breakdown', inplace=True)\n",
    "t3['produksi_status'].fillna('Breakdown', inplace=True)\n",
    "\n",
    "t3_bd = t3[t3.project=='Breakdown']\n",
    "t3_bd = t3_bd[t3_bd.cost!=0]\n",
    "t3_ac = t3[t3.project!='Breakdown']\n",
    "t3 = pd.concat([t3_bd, t3_ac])\n",
    "t3 = t3.sort_values('date', ascending=False).reset_index(drop=True)\n",
    "t3['produksi'] = t3['produksi']/1000\n",
    "t3.to_excel('./Report/task3.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a40148-8bb3-4005-9350-01dd8ed7f129",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Task 4 : DASHBOARD\n",
    "Kumpulkan trend data produksi dan bandingkan dengan maximal muatan nya "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8184180-04ee-4cae-b695-3053d25e1de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 287.75it/s]\n"
     ]
    }
   ],
   "source": [
    "c2 = kpi.copy()\n",
    "c2 = c2[c2['project/name']!='-']\n",
    "c2 = c2[c2.retase>0]\n",
    "c2['count_sheet'] = c2['production'].apply(lambda x: len(str(x).split(';')))\n",
    "c2['target_produksi'] = c2.count_sheet * c2.kapasitas_maximal\n",
    "c2 = c2[c2.target_produksi!=0]\n",
    "c2 = c2[['date','project/name','production','move_type','spk_project','category_equipment','equipment_name','name','standar_jarak','jam_produktivitas','jam_breakdown','jam_standby','kapasitas_maximal','produksi','target_produksi','retase','total_jarak_tempuh','count_sheet']]\n",
    "\n",
    "def get_different(retase, c_spk_kerja, produksi, target_produksi):\n",
    "    retase_round = np.round(retase)\n",
    "    \n",
    "    con = retase_round == c_spk_kerja\n",
    "    diff = c_spk_kerja - retase\n",
    "    p_diff = diff / c_spk_kerja\n",
    "\n",
    "    selisih_target = target_produksi - produksi\n",
    "    p_selisih_target = selisih_target/target_produksi\n",
    "\n",
    "    msg = {\n",
    "        'condition':[con],\n",
    "        'diff':[diff],\n",
    "        'p_diff':[p_diff],\n",
    "        'selisih_target_produksi':[selisih_target],\n",
    "        'p_selisih_target_produksi':[p_selisih_target]\n",
    "    }\n",
    "\n",
    "    return msg\n",
    "\n",
    "ret = c2.iloc[0]['retase']\n",
    "count_sheet = c2.iloc[0]['count_sheet']\n",
    "produksi = c2.iloc[0]['produksi']\n",
    "target_produksi = c2.iloc[0]['target_produksi']\n",
    "\n",
    "c2['retase_berbeda'] = c2.apply(lambda x: get_different(x.retase, x.count_sheet, x.produksi, x.target_produksi)['condition'][0], axis=1)\n",
    "c2['selisih_retase_berbeda'] = c2.apply(lambda x: get_different(x.retase, x.count_sheet, x.produksi, x.target_produksi)['diff'][0], axis=1)\n",
    "c2['p_selisih_retase_berbeda'] = c2.apply(lambda x: get_different(x.retase, x.count_sheet, x.produksi, x.target_produksi)['p_diff'][0], axis=1)\n",
    "c2['selisih_target_produksi'] = c2.apply(lambda x: get_different(x.retase, x.count_sheet, x.produksi, x.target_produksi)['selisih_target_produksi'][0], axis=1)\n",
    "c2['p_selisih_target_produksi'] = c2.apply(lambda x: get_different(x.retase, x.count_sheet, x.produksi, x.target_produksi)['p_selisih_target_produksi'][0], axis=1)\n",
    "\n",
    "# eda1 akan menunjukan grafik perbedaan muatan yang diproduksi dengan yang sebenarnya dapat tercapai.\n",
    "eda1 = c2[['date','spk_project','move_type','equipment_name','name','kapasitas_maximal','produksi','retase','count_sheet']].rename(columns={\n",
    "    'kapasitas_maximal':'kapasitas'\n",
    "})\n",
    "eda1['retase'] = eda1['retase'].apply(lambda x: int(np.round(x)))\n",
    "\n",
    "# retase didapatkan dengan cara membagi hasil produksi dengan kapasitas DT\n",
    "# apabila kapasitas DT di maksimalkan maka semestinya akan diperoleh hasil produksi yang maksimal kita nama produksi maksimal\n",
    "eda1['produksi_max_retase'] = eda1.retase * eda1.kapasitas\n",
    "\n",
    "# count_sheet merupakan jumlah sheet yang dibuat oleh operator. Umum nya jumlah sheet ini mewakili banyak retase yang dilakukan. Selanjutnya kita akan hitung berapa hasil maksimal dari banyak sheet apabila menggunakan maksimal muatas yang kita namai sebagai produksi max count sheet\n",
    "eda1['produksi_max_count_sheet'] = eda1.count_sheet * eda1.kapasitas\n",
    "\n",
    "eda1 = eda1.groupby(['date','spk_project','move_type','equipment_name','name'])[['kapasitas','produksi','retase','count_sheet','produksi_max_retase','produksi_max_count_sheet']].sum().reset_index()\n",
    "\n",
    "cols = ['produksi','retase','count_sheet','produksi_max_retase','produksi_max_count_sheet']\n",
    "\n",
    "eda2_ = []\n",
    "for i in tqdm(cols):\n",
    "    data = eda1.copy()\n",
    "    values = data[i].tolist()\n",
    "    data['status'] = i\n",
    "    data = data[['date','spk_project','move_type','equipment_name','name','kapasitas','status']]\n",
    "    data['value'] = values\n",
    "    eda2_.append(data)\n",
    "\n",
    "eda2 = pd.concat(eda2_)\n",
    "\n",
    "eda2['produksi_status'] = eda2.move_type.apply(get_produksi_status)\n",
    "eda2.to_excel('./Report/task5_1.xlsx', index=False)\n",
    "eda1.to_excel('./Report/task5_2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97439bc2-f255-44a9-a7ee-957ce5b9197f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Task 5 : DASHBOARD\n",
    "- Dashboard Monitoring Prodical Maintenance Equipment\n",
    "- Rerata Equipment harus masuk dalam periodical Maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7f350204-798c-4f2a-bb45-5df9b2113f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>equipment_name</th>\n",
       "      <th>description</th>\n",
       "      <th>oil_consumption</th>\n",
       "      <th>standar_hm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KOMATSU HM400-3R</td>\n",
       "      <td>oli engine</td>\n",
       "      <td>64.0</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KOMATSU HM400-3R</td>\n",
       "      <td>oli transmisi</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KOMATSU HM400-3R</td>\n",
       "      <td>final driver</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KOMATSU HM400-3R</td>\n",
       "      <td>diffrential</td>\n",
       "      <td>106.0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KOMATSU HM400-3R</td>\n",
       "      <td>hyraulick</td>\n",
       "      <td>167.0</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     equipment_name     description  oil_consumption  standar_hm\n",
       "0  KOMATSU HM400-3R      oli engine             64.0         350\n",
       "1  KOMATSU HM400-3R  oli transmisi             156.0        1000\n",
       "2  KOMATSU HM400-3R    final driver             32.0        2000\n",
       "3  KOMATSU HM400-3R     diffrential            106.0        2000\n",
       "4  KOMATSU HM400-3R       hyraulick            167.0        3000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show table periodical\n",
    "tbl_periodical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c0010799-c031-4dfe-b872-87fd2ade3ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kumpul data historical dari setiap alat\n",
    "bd7 = df[['spk','broken','category_equipment','equipment_name','equipment_code','hm']]\n",
    "ts7 = df2[['name','date','equipment','hm_engine_start','hm_engine_end','actual_engine']]\n",
    "\n",
    "# transform data\n",
    "bd7['name'] = bd7['equipment_code'].apply(lambda x: str(x).split('/')[0])\n",
    "bd7 = bd7.rename(columns={'spk':'spk','broken':'date','hm':'hm_engine_end'})\n",
    "bd7 = bd7.drop(columns=['equipment_code'])\n",
    "bd7['status'] = 'b/d'\n",
    "bd7 = bd7[['status','spk','date','category_equipment','equipment_name','name','hm_engine_end']]\n",
    "\n",
    "ts7 = ts7.rename(columns={'name':'spk','equipment':'name'})\n",
    "ts7['name'] = ts7['name'].apply(lambda x: str(x).split('/')[0])\n",
    "\n",
    "# merge data\n",
    "ts7 = ts7.merge(bd7[['category_equipment','equipment_name','name']].drop_duplicates(), on='name', how='left')\n",
    "ts7['status'] = 'timesheet'\n",
    "ts7 = ts7[['status','spk','date','category_equipment','equipment_name','name','hm_engine_end']]\n",
    "\n",
    "# concat all data time sheet and data breadown\n",
    "t7 = pd.concat([ts7,bd7])\n",
    "t7['date'] = pd.to_datetime(t7.date).dt.date\n",
    "# t7 = t7[pd.to_datetime(t7.date).dt.year>2023]\n",
    "\n",
    "# kita asumsikan data tidak terdapat human error\n",
    "t7 = t7[t7.hm_engine_end!=0]\n",
    "\n",
    "t7 = t7.sort_values(['name','date','hm_engine_end'], ascending=True)\n",
    "t7 = t7.drop_duplicates(subset=['date','category_equipment','equipment_name','name','hm_engine_end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a4f995bf-a0e3-46cb-b26b-dda7b8cdbeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data untuk uji program\n",
    "\n",
    "list_unit_hino_zy = t7[t7.equipment_name=='HINO ZY'].name.unique().tolist()\n",
    "sample = t7[t7.name==list_unit_hino_zy[20]]\n",
    "\n",
    "# cleaning data\n",
    "sample['pct_change'] = sample.hm_engine_end.pct_change()\n",
    "sample = sample[sample['pct_change']>0]\n",
    "sample = sample[sample['pct_change']<sample['pct_change'].median()]\n",
    "sample = sample[pd.to_datetime(sample.date).dt.year>=2024]\n",
    "sample.drop(columns='pct_change', inplace=True)\n",
    "\n",
    "def get_increase_hm(list_hm):\n",
    "    msg = []\n",
    "    for i in range(len(list_hm)):\n",
    "        try:\n",
    "            value = list_hm[i + 1] - list_hm[i]\n",
    "            msg.append(value)\n",
    "        except:\n",
    "            msg.append(None)\n",
    "    msg = [0] + msg[:-1]   \n",
    "    return msg\n",
    "\n",
    "# apply function\n",
    "sample['increase_hm'] = get_increase_hm(sample.hm_engine_end.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "726adc61-e298-4234-9b5b-3ecbab3676e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cek_periode_ganti(hm_engine_end, eq_name):\n",
    "    base = tbl_periodical[tbl_periodical.equipment_name==eq_name].reset_index(drop=True)\n",
    "    base['params'] = [0 for i in range(len(base))]\n",
    "    \n",
    "    increase_hm = get_increase_hm(hm_engine_end)\n",
    "    msg = []\n",
    "    for i in increase_hm:\n",
    "        # buat perulangan untuk menambahkan params\n",
    "        for k in range(len(base)):\n",
    "            base['params'][k] = base['params'][k] + i\n",
    "            \n",
    "        base['con'] = base.params >= base.standar_hm\n",
    "        if True in base['con'].tolist():\n",
    "            n = base[base.con == True]\n",
    "            index_list = n.index.tolist()\n",
    "            for j in index_list:\n",
    "                base['params'][j] = 0\n",
    "            msg.append(','.join(n.description.tolist()))\n",
    "        else:\n",
    "            msg.append(np.NaN)\n",
    "\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac81596-a7b6-47d8-b576-ee152989344c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9fa87f68-139d-4464-bd0b-0b8c09e849bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 355/355 [00:22<00:00, 16.02it/s]\n"
     ]
    }
   ],
   "source": [
    "t7_ = []\n",
    "for i in tqdm(t7.name.unique().tolist()):\n",
    "    n = t7[t7.name==i]\n",
    "    # n = n[pd.to_datetime(n.date).dt.year>=2024]\n",
    "    \n",
    "    hm_list = n['hm_engine_end'].tolist()\n",
    "    eq_name = n['equipment_name'].unique().tolist()[0]\n",
    "    \n",
    "    n['periodical_maintenance'] = cek_periode_ganti(hm_list, eq_name)\n",
    "    t7_.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1090db98-72fa-4faa-971e-87e45fbf7120",
   "metadata": {},
   "outputs": [],
   "source": [
    "t7 = pd.concat(t7_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5d5b2ebc-4cae-49c8-966d-4fff65adf311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>periodical_maintenance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th>periodical_maintenance</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D65-02</th>\n",
       "      <th>engine</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D65-07</th>\n",
       "      <th>engine</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">D65-10</th>\n",
       "      <th>damper,final driver,transmission</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engine</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engine,damper,final driver,transmission</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">SK330-11</th>\n",
       "      <th>engine</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engine,hyraulick,swing machinery,final driver</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engine,swing machinery,final driver</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SK330-12</th>\n",
       "      <th>engine,hyraulick,swing machinery,final driver</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engine,swing machinery,final driver</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        periodical_maintenance\n",
       "name     periodical_maintenance                                               \n",
       "D65-02   engine                                                              2\n",
       "D65-07   engine                                                              1\n",
       "D65-10   damper,final driver,transmission                                    1\n",
       "         engine                                                              3\n",
       "         engine,damper,final driver,transmission                             1\n",
       "...                                                                        ...\n",
       "SK330-11 engine                                                              2\n",
       "         engine,hyraulick,swing machinery,final driver                       2\n",
       "         engine,swing machinery,final driver                                 2\n",
       "SK330-12 engine,hyraulick,swing machinery,final driver                       1\n",
       "         engine,swing machinery,final driver                                 1\n",
       "\n",
       "[498 rows x 1 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t7.groupby(['name','periodical_maintenance'])[['periodical_maintenance']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e0d2c983-953a-401f-b9d3-533e96bc45f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = t7[t7.name=='D65-10'].periodical_maintenance.value_counts().reset_index().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b629f245-4864-4a71-82d7-55af09e8cc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ubah kolom 'index' menjadi unik\n",
    "unique_index = []\n",
    "for index_list in check['index'].values():\n",
    "    unique_index.extend(index_list.split(','))\n",
    "\n",
    "unique_index = sorted(set(unique_index))\n",
    "\n",
    "# Buat DataFrame baru dengan indeks unik\n",
    "new_data = {\n",
    "    'index': [', '.join(unique_index)] * len(check['index']),\n",
    "    'periodical_maintenance': check['periodical_maintenance'].values()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2ade95fc-7d1f-4cde-9c59-5c62adbf1097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>periodical_maintenance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>damper, engine, final driver, hyraulick, trans...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>damper, engine, final driver, hyraulick, trans...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>damper, engine, final driver, hyraulick, trans...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>damper, engine, final driver, hyraulick, trans...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               index  periodical_maintenance\n",
       "0  damper, engine, final driver, hyraulick, trans...                       3\n",
       "1  damper, engine, final driver, hyraulick, trans...                       1\n",
       "2  damper, engine, final driver, hyraulick, trans...                       1\n",
       "3  damper, engine, final driver, hyraulick, trans...                       1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1092de0f-9805-46bb-a7b9-d3303053dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = t1[pd.to_datetime(t1.done).dt.strftime('%m/%y').isin(['02/23'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ea479d0-6edc-414f-9ef1-d6a4e4bdcd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rp 4.475.284.124,0'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rupiah(check[check.requirement_type=='External'].cost.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "002bf3b4-7f9c-48b9-99ee-58e7810b32a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "check[check.requirement_type=='External'].to_excel('check_external.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab924d-4c0c-4776-b99a-3f530155de13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Task 6 : DASHBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a60bc199-5a6b-4be8-99b6-88db43c91b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 289.87it/s]\n"
     ]
    }
   ],
   "source": [
    "t10 = t3.copy()\n",
    "\n",
    "# KONTRAK KBM : MINING KBM\n",
    "# KONTRAK BLOK 8 : MINIM BDM\n",
    "# RENTAL BLOK 8 : [RENTAL BDM] [BLOK 5 - PABRIK]\n",
    "# RENTAL FEEDING KM 7 : [RENTAL BDM] [KM7 - PABRIK]\n",
    "\n",
    "def get_kontrak(project, move):\n",
    "    if project == 'Mining KBM':\n",
    "        msg = 'Kontrak KBM'\n",
    "        \n",
    "    elif project == 'Mining BDM':\n",
    "        msg = 'Kontrak Blok 8'\n",
    "        \n",
    "    elif project == 'Rental BDM':\n",
    "        if move == 'BLOK 5 - PABRIK':\n",
    "            msg = 'Rental Blok 8'\n",
    "            \n",
    "        elif move == 'KM7 - PABRIK':\n",
    "            msg = 'Feeding KM7'\n",
    "            \n",
    "        else:\n",
    "            msg = 'Tidak Diketahui'\n",
    "\n",
    "    else:\n",
    "        msg = 'Tidak Diketahui'\n",
    "    return msg\n",
    "\n",
    "# APPLY FUNCTION\n",
    "t10['kontrak'] = t10.apply(lambda x: get_kontrak(x.project, x.move_type), axis=1)\n",
    "t10 = t10[t10.kontrak!='Tidak Diketahui']\n",
    "t10 = t10[['date','kontrak','move_type','equipment_name','equipment_detail','in_weight','out_weight','produksi','cost']]\n",
    "\n",
    "# mengisi tanggal kosong pada masing-masing kontrak\n",
    "_ = []\n",
    "for i in tqdm(t10.kontrak.unique().tolist()):\n",
    "    n = t10[t10.kontrak == i]\n",
    "\n",
    "    move = n.move_type.unique().tolist()[0]\n",
    "\n",
    "    n = date.merge(n, on='date', how='left')\n",
    "    n['kontrak'].fillna(i, inplace=True)\n",
    "    n['move_type'].fillna(move, inplace=True)\n",
    "    n['equipment_name'].fillna('Tidak Diketahui', inplace=True)\n",
    "    n['equipment_detail'].fillna('Tidak Diketahui', inplace=True)\n",
    "    n['in_weight'].fillna(0, inplace=True)\n",
    "    n['out_weight'].fillna(0, inplace=True)\n",
    "    n['produksi'].fillna(0, inplace=True)\n",
    "    n['cost'].fillna(0, inplace=True)\n",
    "    _.append(n)\n",
    "\n",
    "t10 = pd.concat(_)\n",
    "t10 = t10.merge(tbl_kapasitas[['equipment_name','kapasitas_maximal']], on='equipment_name', how='left')\n",
    "t10['retase'] = t10.produksi / t10.kapasitas_maximal\n",
    "t10['kapasitas_maximal'].fillna(0, inplace=True)\n",
    "t10['retase'].fillna(0, inplace=True)\n",
    "t10.to_excel('./Report/dashboard_request_pak_jon_1.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6639b32-36b9-4bdc-9127-861e3cd8fb74",
   "metadata": {},
   "source": [
    "# **CC : Cost Control**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cdbdfe-a8f9-45ef-9e0c-e60285066cd3",
   "metadata": {},
   "source": [
    "## CC1 : Summary of Working Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5a74fa45-6717-4476-ba9f-134c0da3caad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 372/372 [00:16<00:00, 22.29it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 329/329 [00:00<00:00, 360.34it/s]\n"
     ]
    }
   ],
   "source": [
    "cc1 = df2.groupby(['date','name','company','project','production','move_type','equipment'])[['hm_engine_start','hm_engine_end']].sum().reset_index()\n",
    "cc1['equipment'] = cc1.equipment.apply(lambda x: str(x).split('/')[0])\n",
    "cc1 = cc1.rename(columns={'name':'ts','equipment':'name'})\n",
    "cc1 = cc1.merge(kpi[['category_equipment','equipment_name','name']].drop_duplicates(), on='name')\n",
    "cc1 = cc1[['date','ts','company','project','production','move_type','category_equipment','equipment_name','name','hm_engine_start','hm_engine_end']]\n",
    "cc1['date'] = pd.to_datetime(cc1.date).dt.date\n",
    "\n",
    "# manipulate data agar sesuai kebutuhan\n",
    "_ = []\n",
    "for i in tqdm(cc1.date.unique().tolist()):\n",
    "    n = cc1[cc1.date == i]\n",
    "    for j in n.name.unique().tolist():\n",
    "        m = n[n.name==j]\n",
    "        count_ret = len(m)\n",
    "        hm = m.head(1).hm_engine_end - m.head(1).hm_engine_start\n",
    "        msg = m.head(1)\n",
    "        msg['hm'] = hm\n",
    "        msg['retase'] = count_ret\n",
    "        _.append(msg)\n",
    "cc1 = pd.concat(_)\n",
    "\n",
    "# isi hari dimana alat tidak dipekerjakan\n",
    "_ = []\n",
    "for i in tqdm(cc1.name.unique().tolist()):\n",
    "    n = cc1[cc1.name==i]\n",
    "    cat_eq = n.category_equipment.unique().tolist()[0]\n",
    "    eq_name = n.equipment_name.unique().tolist()[0]\n",
    "    name = i\n",
    "    n = date.merge(n, on='date', how='outer')\n",
    "    n['ts'].fillna('-', inplace=True)\n",
    "    n['company'].fillna('-', inplace=True)\n",
    "    n['project'].fillna('-', inplace=True)\n",
    "    n['production'].fillna('-', inplace=True)\n",
    "    n['move_type'].fillna('-', inplace=True)\n",
    "    n['category_equipment'].fillna(cat_eq, inplace=True)\n",
    "    n['equipment_name'].fillna(eq_name, inplace=True)\n",
    "    n['name'].fillna(i, inplace=True)\n",
    "    n['hm_engine_start'].fillna(0, inplace=True)\n",
    "    n['hm_engine_end'].fillna(0, inplace=True)\n",
    "    n['hm'].fillna(0, inplace=True)\n",
    "    n['retase'].fillna(0, inplace=True)\n",
    "    _.append(n)\n",
    "    \n",
    "cc1 = pd.concat(_)\n",
    "cc1['plan_hm'] = 10\n",
    "cc1 = cc1.groupby(['date','company','project','production','move_type','category_equipment','equipment_name','name'])[['hm','plan_hm']].sum().reset_index()\n",
    "\n",
    "# pisahkan actual\n",
    "cc1_actual = cc1.drop(columns='plan_hm')\n",
    "cc1_actual['status'] = 'Actual'\n",
    "cc1_actual = cc1_actual.rename(columns={'hm':'values'})\n",
    "\n",
    "# pisahkan plan\n",
    "cc1_plan = cc1.drop(columns='hm')\n",
    "cc1_plan['status'] = 'Plan'\n",
    "cc1_plan = cc1_plan.rename(columns={'plan_hm':'values'})\n",
    "\n",
    "# gabung dengan menambahkkan kolom status\n",
    "cc1 = pd.concat([cc1_actual, cc1_plan])\n",
    "\n",
    "# save data\n",
    "cc1.to_excel('./Report/cc dashboard 1.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e91dbb-cc90-4f12-986c-05264478b32b",
   "metadata": {},
   "source": [
    "## CC2 : Owning & Operation Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "8d5c030d-3a63-4051-9335-d7f97a555a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dapatkan nilai HM total per unit \n",
    "eq_hm = kpi.copy()\n",
    "eq_hm = eq_hm.groupby(['date','category_equipment','equipment_name','name'])[['jam_produktivitas']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "5e7dda36-a7cb-492e-a378-adea0b7f1fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dapatkan nilai rm dengan memisahkan semua biaya ganti ban\n",
    "rm = t1.copy()\n",
    "rm = rm[['company','done','stage','category_equipment','equipment_name','name','requirement_type','category_maintenance','description_2','cost']]\n",
    "rm['date'] = pd.to_datetime(rm['done']).dt.date\n",
    "rm['description2'] = rm['description_2'].apply(lambda x: str(x).split('] ')[-1])\n",
    "rm['description1'] = rm.description2.apply(lambda x: ' '.join(str(x).split()[:2]))\n",
    "rm.drop(columns=['description_2','done'], inplace=True)\n",
    "rm = rm[rm.stage=='DONE']\n",
    "rm = rm[rm.description1!='BAN LUAR']\n",
    "rm = rm[['date','company','stage','category_equipment','equipment_name','name','requirement_type','category_maintenance','description2','cost']]\n",
    "rm = rm.groupby(['date','company','category_equipment','equipment_name','name'])[['cost']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c6325b1f-349a-4f6d-88f1-f831f7ce6abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamps</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>project</th>\n",
       "      <th>production</th>\n",
       "      <th>name</th>\n",
       "      <th>konsumsi</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-05-22 13:21:25.920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-05-16 00:00:00</td>\n",
       "      <td>Rental KBM</td>\n",
       "      <td>Quarry Mined</td>\n",
       "      <td>DT-22</td>\n",
       "      <td>15</td>\n",
       "      <td>DICKY 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamps   id                 date     project    production  \\\n",
       "0 2024-05-22 13:21:25.920  0.0  2024-05-16 00:00:00  Rental KBM  Quarry Mined   \n",
       "\n",
       "    name konsumsi     user  \n",
       "0  DT-22       15  DICKY 1  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dapatkan nilai fuel\n",
    "url_konsumsi = \"https://docs.google.com/spreadsheets/d/1Q9nZYOoRZZL_PB6wUPDyBtzuWJv2qZXpbXYlt7wrGho/export?format.xlsx\"\n",
    "\n",
    "try:\n",
    "    os.remove('fuel_comsumption.xlsx')\n",
    "except:\n",
    "    None\n",
    "    \n",
    "output_filename = 'fuel_comsumption.xlsx'\n",
    "\n",
    "# get the data from spreadsheet\n",
    "response = requests.get(url_konsumsi)\n",
    "if response.status_code == 200:\n",
    "    with open(output_filename, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "# read data\n",
    "fuel = pd.read_excel(output_filename)\n",
    "fuel = fuel[fuel.index>0].reset_index(drop=True).drop(columns='CODE USER')\n",
    "fuel.columns = ['_'.join(i.lower().split()) for i in fuel.columns]\n",
    "fuel.rename(columns={'id_unit':'name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "ff934faf-3f46-4ba9-9bf6-1982377bb769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamps</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>project</th>\n",
       "      <th>production</th>\n",
       "      <th>id_unit</th>\n",
       "      <th>konsumsi</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-05-22 13:21:25.920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-05-16 00:00:00</td>\n",
       "      <td>Rental KBM</td>\n",
       "      <td>Quarry Mined</td>\n",
       "      <td>DT-22</td>\n",
       "      <td>15</td>\n",
       "      <td>DICKY 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamps   id                 date     project    production  \\\n",
       "0 2024-05-22 13:21:25.920  0.0  2024-05-16 00:00:00  Rental KBM  Quarry Mined   \n",
       "\n",
       "  id_unit konsumsi     user  \n",
       "0   DT-22       15  DICKY 1  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4a8bcf-98dd-42b7-9ced-676b894d3436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b64c869-66e2-44b0-a2df-c17785e42fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
